{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de67ed4-96d3-403f-a82b-76df5cee40eb",
   "metadata": {},
   "source": [
    "Access pixel values generally in range of (0,255)\n",
    "1. to access only blue pixel 208\n",
    "2. to access only green pixel 206\n",
    "3. to access only red pixel 205\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a506dc1-ff67-4e32-a841-c32a26e842ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "182253d6-9167-4540-8ba8-11bb8b2d8aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142  84  55]\n"
     ]
    }
   ],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "pix = img[100,100] # location of the pixel\n",
    "print(pix) # rgb pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11e83a5-e98f-46b7-b54f-a346b6d99c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "blue = img[100,100,0]\n",
    "print(blue) # printing pixel value of blue color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2406ff9d-eb87-46a8-b195-8dea48126641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[255 255 255]\n"
     ]
    }
   ],
   "source": [
    "img[100,100] = [255,255,255]\n",
    "print(img[100,100]) # printing changed pixel values at location (100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04633211-e159-486e-b585-bef969616e8e",
   "metadata": {},
   "source": [
    "# Access image properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9efcb8-3c88-48b5-94a0-bb4237cf85b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB Shape : (1200, 1920, 3) \n",
      "\n",
      "ARGB Shape : (1200, 1920, 3) \n",
      "\n",
      "Gray scale Shape : (1200, 1920)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(img_path,cv2.IMREAD_COLOR) # to read in color\n",
    "alpha_img =  cv2.imread(img_path,cv2.IMREAD_UNCHANGED) # gives alpha image\n",
    "gray_img =  cv2.imread(img_path,cv2.IMREAD_GRAYSCALE) # gives image directly in gray scale\n",
    "\n",
    "print(f'RGB Shape : {img.shape}', '\\n')\n",
    "print(f'ARGB Shape : {alpha_img.shape}','\\n')\n",
    "print(f'Gray scale Shape : {gray_img.shape}') # here color channels are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "726d0867-11ca-4836-868a-ea0bcbdc01b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB dtype : uint8 \n",
      "\n",
      "ARGB dtype : uint8 \n",
      "\n",
      "Gray scale dtype : uint8\n"
     ]
    }
   ],
   "source": [
    "# printing dtypes\n",
    "\n",
    "print(f'RGB dtype : {img.dtype}', '\\n')\n",
    "print(f'ARGB dtype : {alpha_img.dtype}','\\n')\n",
    "print(f'Gray scale dtype : {gray_img.dtype}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa87071-7b61-4a6a-bb8a-cc4e779db301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGB size : 6912000 \n",
      "\n",
      "ARGB size : 6912000 \n",
      "\n",
      "Gray scale size : 2304000\n"
     ]
    }
   ],
   "source": [
    "# size of images\n",
    "\n",
    "print(f'RGB size : {img.size}', '\\n')\n",
    "print(f'ARGB size : {alpha_img.size}','\\n')\n",
    "print(f'Gray scale size : {gray_img.size}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d601f-f241-44d0-8111-b36a129aae05",
   "metadata": {},
   "source": [
    "# Setting region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cefc5f98-3495-4ba1-808c-1a28fca8dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "roi = cv2.selectROI(img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d3aa76d-5dd2-4df4-961c-c0141ac460da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping selected roi\n",
    "\n",
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "roi = cv2.selectROI(img)\n",
    "\n",
    "roi_crop = img[int(roi[1]):int(roi[1]+roi[3]),int(roi[0]):int(roi[0] + roi[2])]\n",
    "cv2.imshow(\"ROI image\",roi_crop)\n",
    "cv2.imwrite('cropped.jpg',roi_crop)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092c10b-e056-480b-8c20-06bf68962625",
   "metadata": {},
   "source": [
    "# Splitting and Merging images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49b93203-34b3-4de2-8744-a79b4fff60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "g ,b, r = cv2.split(img)\n",
    "cv2.imshow('Green part of the image', g)\n",
    "cv2.imshow('Blue part of the image', b)\n",
    "cv2.imshow('Red part of the image', r)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0a96c3e-fe5b-4b51-b8c7-04924d70280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging images\n",
    "\n",
    "img1 = cv2.merge((g,b,r))\n",
    "cv2.imshow('Image after merger of 3 colors',img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98a643-9987-4eb3-95a7-032f33c23276",
   "metadata": {},
   "source": [
    "# Changing image color scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a0a7c04-f8b0-4258-a019-7ca2c7ecd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "color_change = cv2.cvtColor(img,cv2.COLOR_RGB2LAB)\n",
    "cv2.imshow('changed color scheme image',color_change)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3108a9a-2ce0-428d-a9bc-819a91aa3717",
   "metadata": {},
   "source": [
    "# Blend two different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c655d9c9-66bd-4eba-aaf4-b86a7eea776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path1 = 'savedimg.jpg'\n",
    "img_path2 = 'luffy.jpg'\n",
    "\n",
    "img1 = cv2.imread(img_path1,cv2.IMREAD_COLOR)\n",
    "img2 = cv2.imread(img_path2,cv2.IMREAD_COLOR)\n",
    "\n",
    "# to blend two images both should be of same size\n",
    "\n",
    "img1 = cv2.resize(img1,(800,600))\n",
    "img2 = cv2.resize(img2,(800,600))\n",
    "\n",
    "blended_img = cv2.addWeighted(img1,0.5,img2,0.5,0.0)\n",
    "cv2.imshow('Blended image',blended_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21b1ac9b-ef37-43b7-b135-4ae94639dcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image saved\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:/Users/prash/Computer_vision/Opencv'\n",
    "\n",
    "filename = 'blended_img.jpg'\n",
    "cv2.imwrite(filename,blended_img)\n",
    "print('image saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bae58f-3380-4397-9afb-3d2eb786e6ca",
   "metadata": {},
   "source": [
    "# Applying different filters on image / masking images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "764e4db3-cee7-441e-9d97-b49150aa4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "k_sharpend = np.array([[-1,-1,-1],# this a filter to sharpen the image\n",
    "                       [-1,9,-1], \n",
    "                       [-1,-1,-1]])\n",
    "\n",
    "sharpened = cv2.filter2D(img,-1,k_sharpend)\n",
    "cv2.imshow('original image',img)\n",
    "cv2.imshow('sharpened image',sharpened)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2e319-eb2d-42ff-a278-9c6e6a3f2f26",
   "metadata": {},
   "source": [
    "# Image Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b50ec3f-b02f-4b81-918c-cbc31c0ded0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ret, threshold = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "canny_image = cv2.Canny(img,50,100)\n",
    "\n",
    "cv2.imshow('original image',img)\n",
    "cv2.imshow('threshold image',threshold)\n",
    "cv2.imshow('canny image',canny_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409f147e-489f-48ca-837b-af9abf29cf12",
   "metadata": {},
   "source": [
    "# Contour detection and shape detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c239e715-5226-41be-9626-008355c8ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'luffy.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "_, threshold = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# contours using findcontours function\n",
    "\n",
    "contours, _ = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "i = 0\n",
    "for contour in contours:\n",
    "    if i == 0:\n",
    "        i = 1\n",
    "        continue\n",
    "    approx = cv2.approxPolyDP(contour,0.01*cv2.arcLength(contour,True),True)\n",
    "    cv2.drawContours(img,[contour],0,(255,0,255),5)\n",
    "    \n",
    "    # finding the center of different shapes\n",
    "    \n",
    "    M = cv2.moments(contour)\n",
    "    if M['m00'] != 0.0:\n",
    "        x = int(M['m10']/M['m00'])\n",
    "        y = int(M['m01']/M['m00'])\n",
    "        \n",
    "    if len(approx) == 3:\n",
    "        cv2.putText(img,'Triangle',(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
    "    elif len(approx) == 4:\n",
    "        cv2.putText(img,'Quadrilateral',(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
    "    elif len(approx) == 5:\n",
    "        cv2.putText(img,'Pentagon',(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
    "    elif len(approx) == 6:\n",
    "        cv2.putText(img,'Hexagon',(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
    "    else:\n",
    "        cv2.putText(img,'circle',(x,y),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n",
    "        \n",
    "cv2.imshow('shapes',img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6999a-6d28-4951-ae6a-0774b0986dd4",
   "metadata": {},
   "source": [
    "# Color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bac7d728-c184-4cc6-9d97-1edbbdba8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# HSV hue saturation value.commonly used in color and paint softwares\n",
    "\n",
    "hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_blue = np.array([0,50,50])\n",
    "upper_blue = np.array([140,255,255])\n",
    "\n",
    "# thershold the hsv image\n",
    "\n",
    "blue_color = cv2.inRange(hsv,lower_blue,upper_blue)\n",
    "res = cv2.bitwise_and(img,img,mask = blue_color)\n",
    "cv2.imshow('res',res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9880b4-5d02-4d9f-a388-0cd6127d1f0b",
   "metadata": {},
   "source": [
    "# Masking a image using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec9e20e6-d241-413a-af69-28ae8037afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "img_path = 'savedimg.jpg'\n",
    "img = cv2.imread(img_path,cv2.IMREAD_COLOR)\n",
    "\n",
    "img1 = img.copy()\n",
    "mask = np.zeros((100,300,3))\n",
    "print(mask.shape)\n",
    "\n",
    "pos = (200,200)\n",
    "var = img1[200:(200+mask.shape[0]),200:(200+mask.shape[1])] = mask\n",
    "cv2.imshow('coloring',img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc57394-45de-4171-b90d-11d78624f7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
